# Optimizing an ML Pipeline in Azure

## Overview
This project is part of the Udacity Azure ML Nanodegree.
In this project, we build and optimize an Azure ML pipeline using the Python SDK and a provided Scikit-learn model.
This model is then compared to an Azure AutoML run.

## Summary
**In 1-2 sentences, explain the problem statement: e.g "This dataset contains data about... we seek to predict..."**

**In 1-2 sentences, explain the solution: e.g. "The best performing model was a ..."**
.
.
The best performing model was the VotingEnsemble model selected through AutoML, which gave an accuracy of 0.91767. 
The Logistic Regression model with hyperparameters selected through HyperDrive gave an accuracy of 9.90996


## Scikit-learn Pipeline
**Explain the pipeline architecture, including data, hyperparameter tuning, and classification algorithm.**

**What are the benefits of the parameter sampler you chose?**
The parameter sampling method chosen for this experimnent is Random Sampling. Randing Sampling supports both discrete and continuous hyperparameters. In Logistic Regression, there are two hyperparameters:
i) inverse of regularization strength which is treated as continuous
ii) maximum number of iterations, which is treated as discrete

Random sampling also supports early termination of low-performance runs. For each of the hyperparameters, hyperparameter space is defined. In this experiment,
i) C (inversion of regularization strength)
    uniform (0.01, 1.00)
    This returns values uniformly distributed between 0.01 and 1.00
ii) max-iter (maximum number of iterations)
    choice (100, 200, 300, 400, 500)
    This returns a value chosen among given discrete values 100, 200, 300, 400, 500
Hyperparameter values are randomly selected from the defined search space.


**What are the benefits of the early stopping policy you chose?**
Automatically terminating poorly performing runs with an early termination policy improves computational efficiency.
In this experiment, Bandit policy is used. Bandit policy is based on slack factor/slack amount and evaluation interval. Bandit terminates runs where the primary metric is not within the specific slack factor/slack amount comapred to the best performing run. 
The primary metric for the experiment is accuracy.

The following configuration parameters were specified:
i) evaluation_interval=2
    The policy is applied every other time the training script logs the primary metric.
ii) delay_evaluation=5
    The first policy evaluation is delayed to avoid premature termination.
iii) slack_factor=0.1
    Any run whose best metric run is less than (1/(1+0.1)) or 91% of the best performing run will be terminated. 

## AutoML
**In 1-2 sentences, describe the model and hyperparameters generated by AutoML.**

The VotingEnsemble model defines an ensemble created from previous AutoML iterations that implements soft voting. The hyperparameters generated are the classifiers for the ensemble and the weights. 

weights=[0.4666666666666667, 0.2, 0.06666666666666667, 0.06666666666666667, 0.06666666666666667, 0.06666666666666667, 0.06666666666666667]
                                                        
                                                        
                                                        
                                                        
                                                    

## Pipeline comparison
**Compare the two models and their performance. What are the differences in accuracy? In architecture? If there was a difference, why do you think there was one?**

## Future work
**What are some areas of improvement for future experiments? Why might these improvements help the model?**

## Proof of cluster clean up
**If you did not delete your compute cluster in the code, please complete this section. Otherwise, delete this section.**
**Image of cluster marked for deletion**
